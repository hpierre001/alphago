{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfbe67f-e334-4201-b1b2-b9ab958ab626",
   "metadata": {},
   "source": [
    "## Environnement setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add83c51-7589-45fe-82bb-6204e4b3773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec76163-5606-49fe-9b53-51f92ca1e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "effc926a-705e-4443-864b-a99f64215dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.1+cu102\n",
      "No GPU :(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(\"GPU found :)\" if torch.cuda.is_available() else \"No GPU :(\")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de12d8c-64da-42ac-9309-5c76c7d4a29c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00cbe89-2430-4a5b-97f1-320050a8fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, n_features, kernel, stride=1, padding='same'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_features, n_features, kernel, padding=padding, stride=stride)\n",
    "        self.norm1 = nn.BatchNorm2d(n_features)\n",
    "        self.conv2 = nn.Conv2d(n_features, n_features, kernel, padding=padding, stride=stride)\n",
    "        self.norm2 = nn.BatchNorm2d(n_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.norm1(y)\n",
    "        y = F.ReLU(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.norm2(y)\n",
    "        x += y\n",
    "        return F.ReLU(x)\n",
    "        \n",
    "\n",
    "class AlphaGoNN(nn.Module):\n",
    "    def __init__(self, dim_board=81, input_dim=15, n_features=64, kernel=3, n_blocks=5, stride=1, padding='same'):\n",
    "        super(AlphaGoNN, self).__init__()\n",
    "        self.input_conv = nn.Conv2d(input_dim, n_features, kernel, padding=padding, stride=stride)\n",
    "        self.input_norm = nn.BatchNorm2d(n_features)\n",
    "        \n",
    "        self.bolcks = [ConvBlock(n_features, kernel, padding=padding, stride=stride) for i in range(n_blocks)]\n",
    "        \n",
    "        self.policy_conv = nn.Conv2d(n_features, 2, 1, padding=padding, stride=stride)\n",
    "        self.policy_norm = nn.BatchNorm2d(2)\n",
    "        self.policy_linear = nn.Linear(2 * dim_board, dim_board + 1)\n",
    "        \n",
    "        self.value_conv = nn.Conv2d(n_features, 1, 1, padding=padding, stride=stride)\n",
    "        self.value_norm = nn.BatchNorm2d(1)\n",
    "        self.value_linear1 = nn.Linear(dim_board, n_features)\n",
    "        self.value_linear2 = nn.Linear(n_features, 1)\n",
    "    \n",
    "    def _policy(self, x):\n",
    "        x = self.policy_conv(x)\n",
    "        x = self.policy_norm(x)\n",
    "        x = F.ReLU(x)\n",
    "        x = self.policy_linear(x)\n",
    "        return x\n",
    "\n",
    "    def _value(self, x):\n",
    "        x = self.value_conv(x)\n",
    "        x = self.value_norm(x)\n",
    "        x = F.ReLU(x)\n",
    "        x = self.value_linear1(x)\n",
    "        x = F.ReLU(x)\n",
    "        x = self.value_linear2(x)\n",
    "        x = F.tanh(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.input_norm(x)\n",
    "        x = F.ReLU(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        p = self._policy(x)\n",
    "        v = self._value(x)\n",
    "        return p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2c8c92-2d16-4ed8-958e-d6dd12bcafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = AlphaGoNN()\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229452e2-b02a-458c-824b-f7829eed2f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
